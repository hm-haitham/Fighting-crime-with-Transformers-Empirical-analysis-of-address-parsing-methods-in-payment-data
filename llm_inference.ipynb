{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be91d6-7c92-41f7-bfbf-1dcabdcc1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/workspace/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef28d6-3309-42e9-8535-9569d600c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ast\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbbd47-4515-4774-abea-4a61fd31f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the model to select here. It can be loaded locally\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = LLM(model=model_id, \n",
    "          max_num_seqs=60,\n",
    "         tensor_parallel_size=1, \n",
    "         dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70591e76-2782-4277-8ce3-cf6954c50c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_func(address):\n",
    "    \n",
    "    template = f\"\"\"<s>[INST]\n",
    "    You are a word classifier that classifies words from a text corresponding to an address free text field.\n",
    "    You should analyze with deep precision the INPUT and return a dictionary with the following keys: \"Name\", \"StreetNumber\", \"StreetName\", \"Municipality\", \"PostalCode\", \"Unit\", \"Country\", \"CountryCode\".\n",
    "    Each word is separated by a space and should be classified without any modification.\n",
    "    Each word in the input has a prefix with the index i as '[i]-' and it should be ignored for the classification but it should remain AS-IS in the output.\n",
    "    Sub sequence of words should be classified as follow:\n",
    "    'Name': words corresponding to an indiviual name or institution name.\n",
    "    'StreetNumber': words corresponding to a street number.\n",
    "    'StreetName': words corresponding to a street name.\n",
    "    'Municipality': words corresponding to a municipality or city.\n",
    "    'PostalCode': words corresponding to a postal code.\n",
    "    'Unit': words corresponding to a unit number.\n",
    "    'Country': words corresponding to a full country name.\n",
    "    'CountryCode': words corresponding to a country iso2 code.\n",
    "    \n",
    "    Output Indicator:\n",
    "    2. Usually a name comes before the address.\n",
    "    3. \"$\" is indicating a large separator and it should not be classified.\n",
    "    4. The output words should be taken from the input only and it should not be modified\n",
    "    5. The same word cannot be used in two different classes.\n",
    "    6. Words are classified subsequently.\n",
    "    7. Empty classes should not appear in the output.\n",
    "    8. Output should not include nested values.\n",
    "    9. Each index are taken from the input itself and the index matches, e.g. the prefix '[i]-' remains unchanged for all words.\n",
    "    \n",
    "    For example:\n",
    "    ### INPUT:\n",
    "    \"[0]-THOMASSEN [1]-GULBRANDSEN [2]-OG [3]-GUNDERSEN [4]-$ [5]-TV [6]-SD [7]-9 [8]-JAPARATINGA [9]-57950 [10]-000 [11]-BR\"\n",
    "    ### OUTPUT: \n",
    "    {{\"Name\": \"[0]-THOMASSEN [1]-GULBRANDSEN [2]-OG [3]-GUNDERSEN\", \"StreetName\": \"[5]-TV [6]-SD [7]-9\", \"Municipality\": \"[8]-JAPARATINGA\", \"PostalCode\": \"[9]-57950 [10]-000\", \"CountryCode\": \"[11]-BR\"}}\n",
    "    \n",
    "    \n",
    "    ### INPUT:\n",
    "    {address}\n",
    "    [/INST]\n",
    "    \n",
    "    ### OUTPUT:\n",
    "    \"\"\"\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49882989-256e-4afb-9c75-415bc45c060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = [\"\\n\\n\",\n",
    "        \"\\n \\n\",\n",
    "        \"\\n  \\n\",\n",
    "        \"\\n   \\n\",\n",
    "        \"\\n    \\n\",\n",
    "        \"\\n     \\n\",\n",
    "        \"\\n      \\n\",\n",
    "        \"\\n       \\n\"]\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.2, top_p=0.5, max_tokens=3000, stop=stop)\n",
    "\n",
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900fcad-1baa-481e-a305-70d66bf8ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"data/V2_test.pkl\", 'rb'))[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c2eb9-5aeb-4c9a-a139-c1940f57c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index and create prompts\n",
    "df[\"full_address\"] = df.apply(lambda row: \" \".join(\"[\" + str(i) + \"]-\" + token for i, token in enumerate(row[\"sentence\"])), axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "full_addresses = df[\"full_address\"].to_dict()\n",
    "full_addresses = [template_func(full_addresses[i]) for i in range(len(full_addresses))]\n",
    "\n",
    "# Using vLLM to do inference\n",
    "outputs = llm.generate(full_addresses[:1000], sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0618e-8e42-4c71-90cc-4f711285fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show example output\n",
    "outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f13ea4-c914-4c38-80b7-279c554fe6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_output(out):\n",
    "  pattern = regex.compile(r'\\{(?:[^{}]|(?R))*\\}')\n",
    "  # cleanup last character\n",
    "  out = re.sub(r\"]$\", \"}\", out)\n",
    "  out_match = pattern.findall(out)\n",
    "  if out_match:\n",
    "      try:\n",
    "          # cleanup some hallucinations\n",
    "          return ast.literal_eval(out_match[0].replace(': \"Cannot be classified as any of the given classes\"', \"\")\n",
    "                                  .replace(\": true\", \"\")\n",
    "                                  .replace(': \"_gaito_spa_ar\"', \"\")\n",
    "                                  .replace(\"{{\", \"{\")\n",
    "                                  .replace(\"}}\", \"}\")\n",
    "                                 )\n",
    "      except:\n",
    "          print(\"No json found in:\" + out)\n",
    "          return {}\n",
    "  else:\n",
    "    print(\"Wrong format:\" + out)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def flatten_json(nested_json):\n",
    "    flattened_json = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "      if type(x) is dict:\n",
    "         for a in x:\n",
    "            flatten(x[a], a)\n",
    "      else:\n",
    "         flattened_json[name] = x\n",
    "\n",
    "    flatten(nested_json)\n",
    "    return flattened_json\n",
    "\n",
    "# Parse LLM output\n",
    "outputs_llm = [flatten_json(parse_output(out.outputs[0].text)) for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc176a7-ab9c-457a-9a5f-996f7f9e6849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_llm_tags(outputs_llm):\n",
    "  \"\"\"\n",
    "  Create the list of tags corresponding to the dictionary of the form {\"tag\": [\"[i]-word\"]}\n",
    "  \n",
    "  Args:\n",
    "      outputs_llm: dictionary of the form {\"tag\": [\"[i]-word\", ...]}\n",
    "\n",
    "  Returns:\n",
    "      List of tags corresponding to each words in the same order as \"sentence\".\n",
    "  \"\"\"\n",
    "  llm_tag_list = []\n",
    "  for i, output_llm in enumerate(outputs_llm):\n",
    "    data_tags = df.loc[i, \"tags\"]\n",
    "    data_words = df.loc[i, \"sentence\"]\n",
    "    llm_tags = [\"OOA\" for tag in data_tags]\n",
    "    for k, v in output_llm.items():\n",
    "      if v and isinstance(v, str):\n",
    "        pattern = regex.compile(r\"(?<=\\[)([0-9]*?)(?=\\])\")\n",
    "        word_pattern = regex.compile(r\"(?<=\\]-).*\")\n",
    "        for word in v.split(\" \"):\n",
    "          id = pattern.findall(word)\n",
    "          s = word_pattern.findall(word)\n",
    "          if s:\n",
    "            idxs = [i for i, x in enumerate(data_words) if x == s[0]]\n",
    "          else:\n",
    "            idxs = [i for i, x in enumerate(data_words) if x == word]\n",
    "            if len(idxs) == 0:\n",
    "              print(word + \" not in input: \" + str(data_words))\n",
    "              continue\n",
    "            if len(idxs) == 1:\n",
    "              llm_tags[idxs[0]] = k\n",
    "            if len(idxs) > 1:\n",
    "              llm_tags[idxs[0]] = k\n",
    "          if id:\n",
    "            idx = int(id[0])\n",
    "            if idx in idxs:\n",
    "              if word[-1] == \"$\":\n",
    "                llm_tags[idx] = \"HardSep\"\n",
    "              else:\n",
    "                llm_tags[idx] = k\n",
    "            else:\n",
    "              if len(idxs) == 1:\n",
    "                print(f\"{str(data_words)}: Label modified for {word}, setting it as {idxs[0]}\")\n",
    "                llm_tags[idxs[0]] = k\n",
    "              else:\n",
    "                print(\"There is an ambiguity for:\" + str(s) + \" in \" + str(data_words) + \" keeping OOA\")\n",
    "          else:\n",
    "            if len(idxs) == 1:\n",
    "              llm_tags[idxs[0]] = k\n",
    "            else:\n",
    "              print(\"There is an ambiguity for:\" + str(s) + \" in \" + str(data_words) + \" keeping OOA\")\n",
    "    llm_tag_list.append(llm_tags)\n",
    "  return llm_tag_list\n",
    "\n",
    "llm_tag_list = get_llm_tags(outputs_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0905e-dff0-4291-ab66-fc3ab8fcec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute F1 score\n",
    "\n",
    "df[\"llm_tags\"] = pd.Series(llm_tag_list)\n",
    "pattern = regex.compile(r\"(?<=-).*\")\n",
    "df[\"label_tags\"] = df.apply(lambda tags: [pattern.findall(tag)[0] for tag in tags[\"tags\"]], axis = 1)\n",
    "\n",
    "df[\"precision\"] = df.apply(lambda x: sum(c == cp for c, cp in zip(x[\"label_tags\"], x[\"llm_tags\"]) if c not in [\"SoftSep\", \"HardSep\"]) / sum([c not in [\"SoftSep\", \"HardSep\"] for c in x[\"label_tags\"]]), axis=1)\n",
    "df[\"recall\"] = df.apply(\n",
    "    lambda x: sum(\n",
    "        [\n",
    "            c == cp != \"OOA\"\n",
    "            for c, cp in zip(x[\"label_tags\"], x[\"llm_tags\"])\n",
    "            if c not in [\"SoftSep\", \"HardSep\"]\n",
    "        ]\n",
    "        )\n",
    "        / sum([c not in [\"HardSep\", \"OOA\"] for c in x[\"label_tags\"]])\n",
    "          if sum([c!=\"OOA\" for c in x[\"label_tags\"]]) !=0\n",
    "          else 1,\n",
    "          axis=1)\n",
    "df[\"f1\"] = df.apply(lambda x: 2*x[\"precision\"] * x[\"recall\"] / (x[\"precision\"] + x[\"recall\"]) if (x[\"precision\"] + x[\"recall\"]) != 0 else 0, axis=1)\n",
    "\n",
    "print(\"F1 score:\", df[\"f1\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe5c0d-f0c9-4ab6-9e9d-5942fd22cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"path/to/results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
